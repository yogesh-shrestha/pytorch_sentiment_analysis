{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eed1bda",
   "metadata": {},
   "source": [
    "## Binary Text Classification - IMDB\n",
    "### (EmbeddingBag Layer, Linear Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d4da5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import EmbeddingBag\n",
    "import torch.nn as nn\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e7d530",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1a4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = IMDB(split='train')\n",
    "\n",
    "def yield_tokens(train_iter):\n",
    "    for _, text in train_iter:\n",
    "        yield tokenizer(text)      \n",
    "        \n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), \n",
    "                                  min_freq=1,\n",
    "                                  specials=[\"<unk>\"])\n",
    "\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6b57ed",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "287302af",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: 0. if x=='neg'else 1.\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "train_iter, test_iter = IMDB()\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for labels, texts in batch:\n",
    "        label_list.append(label_pipeline(labels))\n",
    "        processed_text = torch.tensor(text_pipeline(texts), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_tensor = torch.tensor(label_list)\n",
    "    label_tensor = torch.unsqueeze(label_tensor, dim=1)\n",
    "    offset_tensor = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_tensor = torch.cat(text_list)\n",
    "    return label_tensor, text_tensor, offset_tensor\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = to_map_style_dataset(train_iter), to_map_style_dataset(test_iter)\n",
    "num_test = int(len(test_dataset)*0.95)\n",
    "split_test, split_valid = random_split(train_dataset, [num_test, len(test_dataset)-num_test])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(split_test, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580ee28",
   "metadata": {},
   "source": [
    "### Define Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba44d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryTextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(BinaryTextClassifier, self).__init__()\n",
    "        self.embedding = EmbeddingBag(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "                \n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        out = self.fc(embedded)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81b61e",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44542079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model):\n",
    "    for labels, texts, offsets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts, offsets)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "            \n",
    "def evaluate(dataloader, model):\n",
    "    n_samples, n_accurates = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for labels, texts, offsets in dataloader:\n",
    "            outputs = model(texts, offsets)\n",
    "            n_accurates += (torch.round(outputs)==labels).sum().item() \n",
    "            n_samples += labels.size(0)\n",
    "    return n_accurates/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a517424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 1/50 | train_accuracy :  0.657 | val_accuracy :  0.650\n",
      "| Epoch: 2/50 | train_accuracy :  0.672 | val_accuracy :  0.661\n",
      "| Epoch: 3/50 | train_accuracy :  0.689 | val_accuracy :  0.688\n",
      "| Epoch: 4/50 | train_accuracy :  0.698 | val_accuracy :  0.698\n",
      "| Epoch: 5/50 | train_accuracy :  0.707 | val_accuracy :  0.708\n",
      "| Epoch: 6/50 | train_accuracy :  0.713 | val_accuracy :  0.716\n",
      "| Epoch: 7/50 | train_accuracy :  0.719 | val_accuracy :  0.722\n",
      "| Epoch: 8/50 | train_accuracy :  0.722 | val_accuracy :  0.730\n",
      "| Epoch: 9/50 | train_accuracy :  0.728 | val_accuracy :  0.734\n",
      "| Epoch: 10/50 | train_accuracy :  0.731 | val_accuracy :  0.735\n",
      "| Epoch: 11/50 | train_accuracy :  0.733 | val_accuracy :  0.738\n",
      "| Epoch: 12/50 | train_accuracy :  0.736 | val_accuracy :  0.740\n",
      "| Epoch: 13/50 | train_accuracy :  0.739 | val_accuracy :  0.743\n",
      "| Epoch: 14/50 | train_accuracy :  0.740 | val_accuracy :  0.745\n",
      "| Epoch: 15/50 | train_accuracy :  0.743 | val_accuracy :  0.747\n",
      "| Epoch: 16/50 | train_accuracy :  0.745 | val_accuracy :  0.749\n",
      "| Epoch: 17/50 | train_accuracy :  0.747 | val_accuracy :  0.751\n",
      "| Epoch: 18/50 | train_accuracy :  0.747 | val_accuracy :  0.751\n",
      "| Epoch: 19/50 | train_accuracy :  0.749 | val_accuracy :  0.754\n",
      "| Epoch: 20/50 | train_accuracy :  0.750 | val_accuracy :  0.754\n",
      "| Epoch: 21/50 | train_accuracy :  0.751 | val_accuracy :  0.758\n",
      "| Epoch: 22/50 | train_accuracy :  0.752 | val_accuracy :  0.758\n",
      "| Epoch: 23/50 | train_accuracy :  0.753 | val_accuracy :  0.759\n",
      "| Epoch: 24/50 | train_accuracy :  0.752 | val_accuracy :  0.756\n",
      "| Epoch: 25/50 | train_accuracy :  0.754 | val_accuracy :  0.760\n",
      "| Epoch: 26/50 | train_accuracy :  0.756 | val_accuracy :  0.763\n",
      "| Epoch: 27/50 | train_accuracy :  0.756 | val_accuracy :  0.762\n",
      "| Epoch: 28/50 | train_accuracy :  0.755 | val_accuracy :  0.761\n",
      "| Epoch: 29/50 | train_accuracy :  0.756 | val_accuracy :  0.762\n",
      "| Epoch: 30/50 | train_accuracy :  0.757 | val_accuracy :  0.763\n",
      "| Epoch: 31/50 | train_accuracy :  0.757 | val_accuracy :  0.762\n",
      "| Epoch: 32/50 | train_accuracy :  0.758 | val_accuracy :  0.765\n",
      "| Epoch: 33/50 | train_accuracy :  0.757 | val_accuracy :  0.762\n",
      "| Epoch: 34/50 | train_accuracy :  0.757 | val_accuracy :  0.761\n",
      "| Epoch: 35/50 | train_accuracy :  0.757 | val_accuracy :  0.762\n",
      "| Epoch: 36/50 | train_accuracy :  0.758 | val_accuracy :  0.762\n",
      "| Epoch: 37/50 | train_accuracy :  0.758 | val_accuracy :  0.763\n",
      "| Epoch: 38/50 | train_accuracy :  0.758 | val_accuracy :  0.762\n",
      "| Epoch: 39/50 | train_accuracy :  0.758 | val_accuracy :  0.764\n",
      "| Epoch: 40/50 | train_accuracy :  0.758 | val_accuracy :  0.762\n",
      "| Epoch: 41/50 | train_accuracy :  0.759 | val_accuracy :  0.763\n",
      "| Epoch: 42/50 | train_accuracy :  0.758 | val_accuracy :  0.763\n",
      "| Epoch: 43/50 | train_accuracy :  0.759 | val_accuracy :  0.762\n",
      "| Epoch: 44/50 | train_accuracy :  0.759 | val_accuracy :  0.764\n",
      "| Epoch: 45/50 | train_accuracy :  0.759 | val_accuracy :  0.766\n",
      "| Epoch: 46/50 | train_accuracy :  0.759 | val_accuracy :  0.766\n",
      "| Epoch: 47/50 | train_accuracy :  0.759 | val_accuracy :  0.764\n",
      "| Epoch: 48/50 | train_accuracy :  0.759 | val_accuracy :  0.764\n",
      "| Epoch: 49/50 | train_accuracy :  0.759 | val_accuracy :  0.764\n",
      "| Epoch: 50/50 | train_accuracy :  0.759 | val_accuracy :  0.765\n",
      "============================================================\n",
      "Test Accuracy:  0.759\n"
     ]
    }
   ],
   "source": [
    "# Define some hyperparameters\n",
    "LR = 0.6\n",
    "N_EPOCHS = 50\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 100\n",
    "classifier = BinaryTextClassifier(vocab_size, embed_dim)\n",
    "\n",
    "# Criterion, Optimizer, learning rate scheduler\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=LR)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train(train_dataloader, classifier)\n",
    "    train_acc = evaluate(train_dataloader, classifier)\n",
    "    valid_acc = evaluate(valid_dataloader, classifier)\n",
    "    scheduler.step()\n",
    "    print(f\"| Epoch: {epoch}/{N_EPOCHS} | train_accuracy : {train_acc: .3f} | val_accuracy : {valid_acc: .3f}\")\n",
    "\n",
    "# Test with test set\n",
    "accu_test = evaluate(test_dataloader, classifier)\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Accuracy: {accu_test: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d8507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
